{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instead of using statistical models like bigrams or trigrams, we will use a Multi-Layer Perceptron (MLP). This is because the array matrix required for storing letter combinations grows exponentially as 26^x, where x is the number of letter combinations. Since 26 represents the number of letters in the alphabet, this approach would require excessive computation and memory. Using a neural network like an MLP is a more efficient alternative.**\n",
    "\n",
    "<div align = 'center'>\n",
    "    <img src=\"./MLP_Arch.png\" width=\"500\">\n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Batch/Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in txt file\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# Convert the alphabet to a index integer using mapping \n",
    "chars = sorted(list(set(''.join(words))))\n",
    "# print(chars)\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0 \n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(stoi)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this following FUnction we are creating a dataset based off of indexs based on the previous mapping and storing them as tensors for each word. For example there is 5 words, so we will end up with a dataset of 5 empty arrays [. . .] and then a variation of all the words as shown in the print out of the funciton: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... -----> e\n",
      "..e -----> m\n",
      ".em -----> m\n",
      "emm -----> a\n",
      "mma -----> .\n",
      "olivia\n",
      "... -----> o\n",
      "..o -----> l\n",
      ".ol -----> i\n",
      "oli -----> v\n",
      "liv -----> i\n",
      "ivi -----> a\n",
      "via -----> .\n",
      "ava\n",
      "... -----> a\n",
      "..a -----> v\n",
      ".av -----> a\n",
      "ava -----> .\n",
      "isabella\n",
      "... -----> i\n",
      "..i -----> s\n",
      ".is -----> a\n",
      "isa -----> b\n",
      "sab -----> e\n",
      "abe -----> l\n",
      "bel -----> l\n",
      "ell -----> a\n",
      "lla -----> .\n",
      "sophia\n",
      "... -----> s\n",
      "..s -----> o\n",
      ".so -----> p\n",
      "sop -----> h\n",
      "oph -----> i\n",
      "phi -----> a\n",
      "hia -----> .\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# This is the block size for how big the input is going to be for the MLP\n",
    "block_size = 3\n",
    "\n",
    "X,y = [],[] # X is the input, y is the Label\n",
    "count = 5\n",
    "for w in words[:5]: \n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    count += len(w)\n",
    "    for ch in w + '.': \n",
    "        ix = stoi[ch]\n",
    "        # print('ch:', ch)\n",
    "        # print('ix', ix)\n",
    "        X.append(context)\n",
    "        # print('context', context)\n",
    "        y.append(ix)\n",
    "        print(''.join([itos[i] for i in context]),'----->', itos[ix])\n",
    "        context = context[1:] + [ix] \n",
    "        \n",
    "print(count)\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Summary:\n",
    "\n",
    "This function converts words into training data by mapping characters to indices and storing them as tensors.  \n",
    "\n",
    "- **Block Size (`3`)**: Defines how many previous characters form the input.  \n",
    "- **`X` (Input) & `y` (Labels)**:  \n",
    "  - `X` stores context windows of size 3.  \n",
    "  - `y` stores the next character for each window.  \n",
    "- **Process**:  \n",
    "  1. Start with an empty context (`[0, 0, 0]`).  \n",
    "  2. Slide through each word (plus `.` at the end).  \n",
    "  3. Store the context in `X` and the next character in `y`.  \n",
    "  4. Shift the context and repeat.  \n",
    "- **Example (`\"emma\"`)**:  \n",
    "  ```\n",
    "  ...  → e  \n",
    "  ..e  → m  \n",
    "  .em  → m  \n",
    "  emm  → a  \n",
    "  mma  → .  \n",
    "  ```  \n",
    "- Finally, `X` and `y` are converted to PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0],\n",
       "         [ 0,  0,  5],\n",
       "         [ 0,  5, 13],\n",
       "         [ 5, 13, 13],\n",
       "         [13, 13,  1]]),\n",
       " tensor([ 5, 13, 13,  1,  0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5], Y[:5] # Printing the first 5 rows of the (X) (Y) tensor\n",
    "\n",
    "# X defines the sequence of characters, and Y defines the next character prediction in the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed before the dataset (X) resulted in 32 total rows, 5 empty intialization rows, and 27 variation rows that determine the next pattern. The block size determines how many characters will be remebered in the sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C is the randome embedding matrix, with 27 rows and 2 columns\n",
    "C = torch.randn((27,2))\n",
    "\n",
    "# Embedding the input tensor X using the embedding matrix C\n",
    "embedding = C[X]\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding Summary**  \n",
    "\n",
    "- **Embeddings map characters to vectors** in a continuous space instead of treating them as separate symbols.  \n",
    "- **Initially random**, embeddings get optimized during training to capture character relationships.  \n",
    "- **Example:** A sequence `[0,0,5]` (where `5 = e`) retrieves vectors from an embedding matrix.  \n",
    "- **Training adjusts these vectors** so similar characters end up closer in space.  \n",
    "- **Benefit:** Helps the model understand patterns and improves predictions without manual rules.\n",
    "\n",
    "<div align = 'center'>\n",
    "    <img src=\"./2d_Vector_Embedding.png\" width=\"500\">\n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6,100)) # This is the weights that will be input to the first layer\n",
    "b1 = torch.randn((100)) # This is the bias that will be input to the first layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We flatten the embeddings from `torch.Size([32, 3, 2]) → torch.Size([32, 6])` to make them compatible for weight multiplication. This is done using `torch.cat`, which concatenates the matrix into a single vector per sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([embedding[:, 0, :], embedding[:, 1, :], embedding[:, 2, :]], 1).shape # Inefficent way of doing it due to new memory being created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the block size changes (e.g., from 3 to 5), the current approach would need manual updates. To avoid hardcoding, we use `torch.unbind`, which dynamically unravels the tensor, making the code more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use of torch.unbind to \n",
    "# torch.unbind(embedding, 1)\n",
    "# This is equivalent to [embedding[:, 0, :], embedding[:, 1, :], embedding[:, 2, :]\n",
    "\n",
    "torch.cat(torch.unbind(embedding, 1), 1).shape\n",
    "# We get the same result as above and it is dynamic for block size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mehtod 2 More efficent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `torch.view()` to reshape the tensor into any desired dimensions. For example, it allows us to convert a tensor from `torch.Size([32, 3, 2])` to `torch.Size([32, 6])` dynamically, making it adaptable to different input shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.view(32,6) # This allows us to make the embedding matrix in a different shape\n",
    "embedding.view(32,6).shape\n",
    "# Testing similarity \n",
    "# embedding.view(32,6) == torch.cat(torch.unbind(embedding, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4224,  0.0806, -0.0831,  ..., -2.2080,  2.0204,  4.3077],\n",
       "        [ 0.4335,  1.1128,  0.3140,  ..., -1.1884,  1.9151,  3.6025],\n",
       "        [-0.1176, -0.3584, -2.7237,  ..., -0.7868,  2.8766,  2.8699],\n",
       "        ...,\n",
       "        [-0.7861,  1.7516,  4.4418,  ..., -6.1124, -2.3208,  2.5561],\n",
       "        [ 3.0018,  2.2580,  9.5165,  ...,  0.7983, -0.6587,  1.3888],\n",
       "        [-0.1440,  2.3041, -0.7475,  ...,  2.3817,  1.4142, -0.1735]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So to multiply the weights with inputs \n",
    "h = embedding.view(32,6) @ W1 + b1\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Multiplies** the **32 input vectors (each of size 6)** with **100 random intialized weights** from `W1 (6, 100)`.  \n",
    "- **Adds bias `b1`** for each of the 32 inputs, resulting in a final shape of `torch.Size([32, 100])`.  \n",
    "\n",
    "This transforms the input into a **100-dimensional hidden representation** for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of hardcoding 32 as the batch size in view(32,6), we can use -1 to make the code adaptable to any batch size. (-1) tells PyTorch to automatically infer the correct batch size based on the input. Input Size = The number of features per sample, Batch Size = The number of samples processed at once in a single forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4224,  0.0806, -0.0831,  ..., -2.2080,  2.0204,  4.3077],\n",
       "        [ 0.4335,  1.1128,  0.3140,  ..., -1.1884,  1.9151,  3.6025],\n",
       "        [-0.1176, -0.3584, -2.7237,  ..., -0.7868,  2.8766,  2.8699],\n",
       "        ...,\n",
       "        [-0.7861,  1.7516,  4.4418,  ..., -6.1124, -2.3208,  2.5561],\n",
       "        [ 3.0018,  2.2580,  9.5165,  ...,  0.7983, -0.6587,  1.3888],\n",
       "        [-0.1440,  2.3041, -0.7475,  ...,  2.3817,  1.4142, -0.1735]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using -1 for dynamic block size\n",
    "h = embedding.view(-1,6) @ W1 + b1\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Softmax Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100,27)) \n",
    "b2 = torch.randn((27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ W2 + b2 # Hidden layers are multiplied by weights of softmax layer and bias are added \n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp() # Taking the exponential of the logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the counts to get the probability of each character\n",
    "prob = counts / counts.sum(1, keepdim=True)\n",
    "print(prob.shape) # should return 32, 27, for 32 sameples and 27 characters\n",
    "\n",
    "print(prob[0].sum()) # The sume of the probabilities should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.2885e-18, 5.5947e-30, 3.1483e-32, 5.7484e-09, 7.4170e-17, 2.6136e-10,\n",
       "        2.5237e-29, 2.6850e-21, 4.5206e-42, 5.2212e-18, 9.2960e-20, 1.8760e-35,\n",
       "        1.3772e-04, 2.2726e-41, 2.8684e-08, 6.2182e-36, 2.0051e-13, 2.5182e-25,\n",
       "        5.6042e-18, 1.0096e-21, 1.2250e-23, 1.4231e-17, 8.7150e-14, 2.4443e-13,\n",
       "        2.9141e-16, 1.0183e-22, 2.5092e-22, 2.1931e-28, 0.0000e+00, 2.7310e-01,\n",
       "        1.5461e-15, 4.5403e-27])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[torch.arange(32), Y] # This is the probability of the correct character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(inf)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = - prob[torch.arange(32), Y].log().mean() # This is the loss function\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaned Up Full MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape # data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "g = torch.Generator().manual_seed(494949) # Seed for reproducibility\n",
    "C = torch.rand((27,2), generator=g) # Random embedding matrix\n",
    "\n",
    "#Step 2\n",
    "W1 = torch.rand((6,100), generator=g) # Random weights for the first layer\n",
    "b1 = torch.rand((100), generator=g) # Random bias for the first layer\n",
    "\n",
    "#Step 3\n",
    "W2 = torch.rand((100,27), generator=g) # Random weights for the Softmax layer\n",
    "b2 = torch.rand((27), generator=g) # Random bias for the Softmax layer\n",
    "params = [C, W1, b1, W2, b2] # Parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Parameters:  3481\n"
     ]
    }
   ],
   "source": [
    "print('Total Number of Parameters: ', sum(p.nelement() for p in params)) # Total number of parameters in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7902)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = C[X] # Embedding the input tensor X using the embedding matrix C\n",
    "h = torch.tanh(embedding.view(-1,6) @ W1 + b1) # Hidden layer\n",
    "logits = h @ W2 + b2 # Logits\n",
    "counts = logits.exp() # Exponential of the logits\n",
    "prob = counts / counts.sum(1, keepdim=True) # Normalizing the counts\n",
    "loss = - prob[torch.arange(32), Y].log().mean() # Loss function\n",
    "loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of manually implementing the **cross-entropy loss function**, we use PyTorch’s built-in `torch.nn.functional.cross_entropy()`, which is more **optimized and efficient**.  \n",
    "\n",
    "Unlike a manual implementation, this **does not create extra tensors** for computation. Instead, it clusters operations together, making it **faster** and more **memory-efficient**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in params: \n",
    "    p.requires_grad_() # Setting the requires_grad to True for all the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2718518376350403\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training the model for 100 epochs\n",
    "for _ in range(1000): \n",
    "    # Forward pass\n",
    "    embedding = C[X] # Embedding the input tensor X using the embedding matrix C\n",
    "    h = torch.tanh(embedding.view(-1,6) @ W1 + b1) # Hidden layer\n",
    "    logits = h @ W2 + b2 # Logits\n",
    "    loss = F.cross_entropy(logits, Y) # Cross entropy loss function\n",
    "    \n",
    "    # Backward pass (Gradient descent)\n",
    "    for p in params: \n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    #update the parameters\n",
    "    for p in params: \n",
    "        p.data += -0.1 * p.grad\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with just **5 words**, the loss dropped from **6.6207 → 0.2613**, but **not to 0**.  \n",
    "\n",
    "This happens because the **first character of each word is unpredictable**—the model starts with an **empty context**, meaning **any letter has an equal probability of being the first prediction**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Training on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the block size for how big the input is going to be for the MLP\n",
    "block_size = 3\n",
    "\n",
    "X,y = [],[] # X is the input, y is the Label\n",
    "\n",
    "for w in words: \n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.': \n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        y.append(ix)\n",
    "        context = context[1:] + [ix] \n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype\n",
    "# Now we have 228146 samples and 3 characters in each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "g = torch.Generator().manual_seed(242424) # Seed for reproducibility\n",
    "C = torch.rand((27,2), generator=g) # Random embedding matrix\n",
    "\n",
    "#Step 2\n",
    "W1 = torch.rand((6,100), generator=g) # Random weights for the first layer\n",
    "b1 = torch.rand((100), generator=g) # Random bias for the first layer\n",
    "\n",
    "#Step 3\n",
    "W2 = torch.rand((100,27), generator=g) # Random weights for the Softmax layer\n",
    "b2 = torch.rand((27), generator=g) # Random bias for the Softmax layer\n",
    "params = [C, W1, b1, W2, b2] # Parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in params: \n",
    "    p.requires_grad_() # Setting the requires_grad to True for all the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.896918296813965\n",
      "4.476920127868652\n",
      "3.65630841255188\n",
      "3.3312156200408936\n",
      "3.1505680084228516\n",
      "3.023245334625244\n",
      "2.9430642127990723\n",
      "2.9014089107513428\n",
      "2.8804824352264404\n",
      "2.8679776191711426\n",
      "2.859326124191284\n",
      "2.8529152870178223\n",
      "2.8479676246643066\n",
      "2.844022512435913\n",
      "2.8407864570617676\n",
      "2.838069200515747\n",
      "2.8357434272766113\n",
      "2.833721399307251\n",
      "2.8319427967071533\n",
      "2.8303616046905518\n",
      "2.828947067260742\n",
      "2.8276729583740234\n",
      "2.8265187740325928\n",
      "2.8254683017730713\n",
      "2.824509620666504\n",
      "2.823629379272461\n",
      "2.8228185176849365\n",
      "2.822068691253662\n",
      "2.82137131690979\n",
      "2.820718765258789\n",
      "2.8201065063476562\n",
      "2.8195266723632812\n",
      "2.818976402282715\n",
      "2.818449020385742\n",
      "2.8179426193237305\n",
      "2.8174526691436768\n",
      "2.816976308822632\n",
      "2.8165109157562256\n",
      "2.8160531520843506\n",
      "2.8156027793884277\n",
      "2.8151557445526123\n",
      "2.814711570739746\n",
      "2.8142688274383545\n",
      "2.8138256072998047\n",
      "2.8133809566497803\n",
      "2.8129336833953857\n",
      "2.812483310699463\n",
      "2.812028169631958\n",
      "2.8115668296813965\n",
      "2.811100959777832\n",
      "2.81062650680542\n",
      "2.8101444244384766\n",
      "2.809652805328369\n",
      "2.809152364730835\n",
      "2.8086416721343994\n",
      "2.808120012283325\n",
      "2.8075854778289795\n",
      "2.807039737701416\n",
      "2.8064796924591064\n",
      "2.805906057357788\n",
      "2.805316925048828\n",
      "2.8047120571136475\n",
      "2.804091453552246\n",
      "2.803452730178833\n",
      "2.8027961254119873\n",
      "2.8021209239959717\n",
      "2.8014261722564697\n",
      "2.8007113933563232\n",
      "2.7999746799468994\n",
      "2.7992165088653564\n",
      "2.7984347343444824\n",
      "2.797630786895752\n",
      "2.796802043914795\n",
      "2.7959492206573486\n",
      "2.7950711250305176\n",
      "2.7941668033599854\n",
      "2.79323673248291\n",
      "2.7922799587249756\n",
      "2.79129695892334\n",
      "2.7902867794036865\n",
      "2.7892489433288574\n",
      "2.788184881210327\n",
      "2.787095308303833\n",
      "2.7859785556793213\n",
      "2.7848379611968994\n",
      "2.7836711406707764\n",
      "2.782482147216797\n",
      "2.7812702655792236\n",
      "2.780038595199585\n",
      "2.778787136077881\n",
      "2.7775187492370605\n",
      "2.7762351036071777\n",
      "2.7749385833740234\n",
      "2.773630380630493\n",
      "2.7723140716552734\n",
      "2.770991802215576\n",
      "2.7696661949157715\n",
      "2.768338203430176\n",
      "2.767012596130371\n",
      "2.7656891345977783\n"
     ]
    }
   ],
   "source": [
    "# (Full-Batch Training)\n",
    "\n",
    "# Training the model for 100 epochs\n",
    "for _ in range(100): \n",
    "    # Forward pass\n",
    "    embedding = C[X] # Embedding the input tensor X using the embedding matrix C\n",
    "    h = torch.tanh(embedding.view(-1,6) @ W1 + b1) # Hidden layer\n",
    "    logits = h @ W2 + b2 # Logits\n",
    "    loss = F.cross_entropy(logits, Y) # Cross entropy loss function\n",
    "    print(loss.item())\n",
    "    # Backward pass (Gradient descent)\n",
    "    for p in params: \n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    #update the parameters\n",
    "    for p in params: \n",
    "        p.data += -0.1 * p.grad\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This process is taking too long because it performs a backward pass on every individual sample. A more efficient and commonly used strategy is to accumulate batches of samples and only run the backward pass on these mini-batches, rather than doing it for each sample or only once every epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Training with Mini-Batch optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 2, 1, 2, 4, 2, 1, 0, 4, 1, 1, 1, 0, 2, 1, 0, 0, 0, 3, 1, 4, 1, 4,\n",
       "        2, 2, 4, 1, 3, 3, 1, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 5, (32,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function generates an array of 32 digits randomly that are between 0-5. We can use this funtionality on to produce minibatches from our dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8847053050994873\n",
      "2.7311527729034424\n",
      "2.916980028152466\n",
      "2.8220932483673096\n",
      "2.950535297393799\n",
      "3.065720319747925\n",
      "2.5892081260681152\n",
      "2.7592172622680664\n",
      "2.979168176651001\n",
      "2.848599433898926\n",
      "2.8047873973846436\n",
      "2.714953660964966\n",
      "2.77398419380188\n",
      "2.7361083030700684\n",
      "3.3289566040039062\n",
      "2.8926572799682617\n",
      "2.781653881072998\n",
      "2.8973894119262695\n",
      "2.707707166671753\n",
      "2.7518696784973145\n",
      "2.8566346168518066\n",
      "2.3971445560455322\n",
      "2.745220899581909\n",
      "2.949542760848999\n",
      "3.1972897052764893\n",
      "2.9162373542785645\n",
      "2.510418176651001\n",
      "3.0068199634552\n",
      "2.8158912658691406\n",
      "2.6291110515594482\n",
      "2.6987574100494385\n",
      "2.972306966781616\n",
      "3.09956955909729\n",
      "2.897442102432251\n",
      "2.4859414100646973\n",
      "2.9215803146362305\n",
      "2.9073636531829834\n",
      "2.756169557571411\n",
      "2.9207074642181396\n",
      "2.5317189693450928\n",
      "2.701770305633545\n",
      "2.9801459312438965\n",
      "2.6830053329467773\n",
      "2.8954803943634033\n",
      "3.0044093132019043\n",
      "2.974919319152832\n",
      "2.7279038429260254\n",
      "3.0028884410858154\n",
      "2.5379905700683594\n",
      "2.782975435256958\n",
      "2.701331377029419\n",
      "2.6398251056671143\n",
      "2.9306960105895996\n",
      "2.486661672592163\n",
      "2.811873435974121\n",
      "2.8283963203430176\n",
      "2.643047571182251\n",
      "2.7480504512786865\n",
      "2.8816280364990234\n",
      "3.0097849369049072\n",
      "2.567183494567871\n",
      "2.766390323638916\n",
      "2.7410662174224854\n",
      "2.6254100799560547\n",
      "3.0129685401916504\n",
      "3.0102548599243164\n",
      "2.944028615951538\n",
      "2.86393404006958\n",
      "2.870905876159668\n",
      "2.7764363288879395\n",
      "2.549592971801758\n",
      "2.6125166416168213\n",
      "2.821192502975464\n",
      "2.629443407058716\n",
      "2.8736047744750977\n",
      "2.5488076210021973\n",
      "2.577894926071167\n",
      "2.648932695388794\n",
      "2.9573891162872314\n",
      "3.1269631385803223\n",
      "2.855693817138672\n",
      "2.5628881454467773\n",
      "2.9083309173583984\n",
      "2.5105457305908203\n",
      "2.8651039600372314\n",
      "2.8839969635009766\n",
      "2.669919490814209\n",
      "2.6414339542388916\n",
      "2.8764617443084717\n",
      "3.1436960697174072\n",
      "2.953122854232788\n",
      "2.58878493309021\n",
      "2.603717803955078\n",
      "2.5667595863342285\n",
      "2.639211893081665\n",
      "2.4959466457366943\n",
      "2.9128243923187256\n",
      "2.569159746170044\n",
      "2.9975788593292236\n",
      "2.6709401607513428\n"
     ]
    }
   ],
   "source": [
    "# (Mini-Batch Training)\n",
    "\n",
    "# Training the model for 100 epochs\n",
    "for _ in range(100): \n",
    "    \n",
    "    #Mini batch Construction\n",
    "    ix = torch.randint(0, X.shape[0], (32,)) # Randomly selecting 32 indexes from dataset storing it in ix\n",
    "    \n",
    "    # Forward pass\n",
    "    embedding = C[X[ix]] # using the randomly selected indexes to get the embedding matrix\n",
    "    h = torch.tanh(embedding.view(-1,6) @ W1 + b1) # Hidden layer\n",
    "    logits = h @ W2 + b2 # Logits\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # Cross entropy loss function\n",
    "    print(loss.item())\n",
    "    # Backward pass (Gradient descent)\n",
    "    for p in params: \n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    #update the parameters\n",
    "    for p in params: \n",
    "        p.data += -0.1 * p.grad\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now using mini-batches the speed dropped from 45 sec. to instant after the mini-batch ruling was applied this drastically reduced computation. \n",
    "\n",
    "- (Mini-Batch Training) significantly reduces computational cost per iteration by only computing gradients on a small subset of the data.\n",
    "- (Full-Batch Training) requires computing gradients over the entire dataset, making it slower and potentially impractical for large datasets.\n",
    "\n",
    "\n",
    "<div align = 'center'>\n",
    "    <img src=\"./Mini-batch_gradient_descent.webp\" width=\"500\">\n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Optimization\n",
    "### Now we will look at the learning rate and how we can find the most optimal solution, common practice cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reset Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the block size for how big the input is going to be for the MLP\n",
    "block_size = 3\n",
    "\n",
    "X,y = [],[] # X is the input, y is the Label\n",
    "\n",
    "for w in words: \n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.': \n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        y.append(ix)\n",
    "        context = context[1:] + [ix] \n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(y)\n",
    "\n",
    "# Step 1\n",
    "g = torch.Generator().manual_seed(242424) # Seed for reproducibility\n",
    "C = torch.rand((27,2), generator=g) # Random embedding matrix\n",
    "\n",
    "#Step 2\n",
    "W1 = torch.rand((6,100), generator=g) # Random weights for the first layer\n",
    "b1 = torch.rand((100), generator=g) # Random bias for the first layer\n",
    "\n",
    "#Step 3\n",
    "W2 = torch.rand((100,27), generator=g) # Random weights for the Softmax layer\n",
    "b2 = torch.rand((27), generator=g) # Random bias for the Softmax layer\n",
    "params = [C, W1, b1, W2, b2] # Parameters for the model\n",
    "\n",
    "for p in params: \n",
    "    p.requires_grad_() # Setting the requires_grad to True for all the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We determine the learing rate from the range 0f 10^-3 to 10^1\n",
    "lre = torch.linspace(-3, 0,10000)\n",
    "lrs = 10**lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4009056091308594"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Mini-Batch Training)\n",
    "\n",
    "lri = [] # Stored list for the learning rate\n",
    "lossi = [] # Loss list of the model for the selected learning rate\n",
    "\n",
    "for i in range(10000): \n",
    "    \n",
    "    #Mini batch Construction\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "    \n",
    "    # Forward pass\n",
    "    embedding = C[X[ix]] \n",
    "    h = torch.tanh(embedding.view(-1,6) @ W1 + b1) \n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y[ix]) \n",
    "\n",
    "    for p in params: \n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    lr = lrs[i]\n",
    "    for p in params: \n",
    "        p.data += -lr * p.grad # The -0.1 here is the learning rate\n",
    "    \n",
    "    lri.append(lre[i])\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lri, lossi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this we can see that the most optimal learning rate is for most optimal results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data - Prevent Overfitting\n",
    "### Best way to prevent overfitting of a LLM is to split the dataset into 3 for training split, dev/validation split, and test split: 80%, 10%, 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is same code as before but now optimized to call for each split dataset\n",
    "def build_dataset(words): \n",
    "    block_size = 3\n",
    "\n",
    "    X,y = [],[]\n",
    "\n",
    "    for w in words: \n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.': \n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            y.append(ix)\n",
    "            context = context[1:] + [ix] \n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(y)\n",
    "    \n",
    "    return X,Y\n",
    "\n",
    "\n",
    "# Setting Model Parameters\n",
    "g = torch.Generator().manual_seed(242424) # Seed for reproducibility\n",
    "C = torch.rand((27,2), generator=g) # Random embedding matrix\n",
    "\n",
    "#Step 2\n",
    "W1 = torch.rand((6,100), generator=g) # Random weights for the first layer\n",
    "b1 = torch.rand((100), generator=g) # Random bias for the first layer\n",
    "\n",
    "#Step 3\n",
    "W2 = torch.rand((100,27), generator=g) # Random weights for the Softmax layer\n",
    "b2 = torch.rand((27), generator=g) # Random bias for the Softmax layer\n",
    "params = [C, W1, b1, W2, b2] # Parameters for the model\n",
    "\n",
    "for p in params: \n",
    "    p.requires_grad_() # Setting the requires_grad to True for all the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 32033\n",
      "Training set range: (0 - 25626)\n",
      "Validation set range: (25626 - 28829)\n",
      "Testing set range: (28829 - 32033)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1222)\n",
    "random.shuffle(words)\n",
    "\n",
    "n1 = int(len(words) * 0.8)\n",
    "n2 = int(len(words) * 0.9)\n",
    "\n",
    "print(f\"Total words: {len(words)}\")\n",
    "print(f\"Training set range: (0 - {n1})\")\n",
    "print(f\"Validation set range: ({n1} - {n2})\")\n",
    "print(f\"Testing set range: ({n2} - {len(words)})\")\n",
    "\n",
    "\n",
    "Xtrain, Ytrain = build_dataset(words[:n1])\n",
    "Xval, Yval = build_dataset(words[n1:n2])\n",
    "Xtest, Ytest = build_dataset(words[n2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([182467, 3]),\n",
       " torch.Size([182467]),\n",
       " torch.Size([22922, 3]),\n",
       " torch.Size([22922]),\n",
       " torch.Size([22757, 3]),\n",
       " torch.Size([22757]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, Ytrain.shape, Xval.shape, Yval.shape, Xtest.shape, Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5406975746154785"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the dataset/labels for the training set\n",
    "Dataset = Xtrain\n",
    "Labels = Ytrain\n",
    "\n",
    "\n",
    "for i in range(30000): \n",
    "    \n",
    "    #Mini batch Construction\n",
    "    ix = torch.randint(0, Dataset.shape[0], (32,))\n",
    "    \n",
    "    # Forward pass\n",
    "    embedding = C[Dataset[ix]] \n",
    "    h = torch.tanh(embedding.view(-1,6) @ W1 + b1) \n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Labels[ix]) \n",
    "\n",
    "    for p in params: \n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    lr = .1 # Learning rate\n",
    "    for p in params: \n",
    "        p.data += -lr * p.grad \n",
    "\n",
    "loss.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Validation set\n",
    "**Testing the model on validation set to see if model is overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3345775604248047"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = C[Xval]\n",
    "h = torch.tanh(embedding.view(-1,6) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdim=True)\n",
    "loss = F.cross_entropy(logits, Yval)\n",
    "loss.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.33760929107666"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = C[Xtest]\n",
    "h = torch.tanh(embedding.view(-1,6) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdim=True)\n",
    "loss = F.cross_entropy(logits, Ytest)\n",
    "loss.item() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we can see that the loss of the Validation and Testing set, are roughly equal. This can indicate that the model is under fitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will need to optimize the network in order to perfrom better, we can do this by increasing the networks parameters to better fit the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing the Size of the N.N. \n",
    "**We can increase the Parameters of the Neural Network, inorder for it to better fit the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing the Neurons in the Hidden Layer (Step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion for the datasets\n",
    "\n",
    "def build_dataset(words): \n",
    "    block_size = 3\n",
    "\n",
    "    X,y = [],[]\n",
    "\n",
    "    for w in words: \n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.': \n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            y.append(ix)\n",
    "            context = context[1:] + [ix] \n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(y)\n",
    "    \n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New # of Parameters: 10281\n"
     ]
    }
   ],
   "source": [
    "# Setting Model Parameters\n",
    "g = torch.Generator().manual_seed(242424) \n",
    "C = torch.rand((27,2), generator=g)\n",
    "\n",
    "#Step 2\n",
    "W1 = torch.rand((6,300), generator=g) # Changed hidden layer neurons from 100 to 300\n",
    "b1 = torch.rand((300), generator=g)  # Changed bias from 100 to 300\n",
    "\n",
    "#Step 3\n",
    "W2 = torch.rand((300,27), generator=g) # Changed softmax layer input from 100 to 300\n",
    "b2 = torch.rand((27), generator=g)\n",
    "params = [C, W1, b1, W2, b2] \n",
    "\n",
    "for p in params: \n",
    "    p.requires_grad_() \n",
    "    \n",
    "print('New # of Parameters:', sum(p.nelement() for p in params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makemore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
